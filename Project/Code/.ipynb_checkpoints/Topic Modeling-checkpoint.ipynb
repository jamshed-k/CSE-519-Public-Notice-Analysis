{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prime\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "FILE = '../Data/all_data.csv'\n",
    "df = pd.DataFrame.from_csv(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>county</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auctions</td>\n",
       "      <td>notice of auction  on friday, march 17, 2017 a...</td>\n",
       "      <td>Pearl River</td>\n",
       "      <td>2017/02/24</td>\n",
       "      <td>2</td>\n",
       "      <td>Picayune Item</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>license suspension</td>\n",
       "      <td>public notice  on october 28, 2015, the pa sta...</td>\n",
       "      <td>Pearl River</td>\n",
       "      <td>2017/02/24</td>\n",
       "      <td>2</td>\n",
       "      <td>Picayune Item</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elections</td>\n",
       "      <td>february 24 legals      notice of special elec...</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>2017/02/24</td>\n",
       "      <td>2</td>\n",
       "      <td>The Ruston Daily Leader</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>auctions</td>\n",
       "      <td>sheriff's sales bank of america na vs. katedra...</td>\n",
       "      <td>St. Bernard</td>\n",
       "      <td>2017/02/24</td>\n",
       "      <td>2</td>\n",
       "      <td>The St. Bernard Voice</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>auctions</td>\n",
       "      <td>sheriff's sales gulf coast bank and trust co v...</td>\n",
       "      <td>St. Bernard</td>\n",
       "      <td>2017/02/24</td>\n",
       "      <td>2</td>\n",
       "      <td>The St. Bernard Voice</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category                                            content  \\\n",
       "0            auctions  notice of auction  on friday, march 17, 2017 a...   \n",
       "1  license suspension  public notice  on october 28, 2015, the pa sta...   \n",
       "2           elections  february 24 legals      notice of special elec...   \n",
       "3            auctions  sheriff's sales bank of america na vs. katedra...   \n",
       "4            auctions  sheriff's sales gulf coast bank and trust co v...   \n",
       "\n",
       "        county        date  month                newspaper        state  year  \n",
       "0  Pearl River  2017/02/24      2            Picayune Item  Mississippi  2017  \n",
       "1  Pearl River  2017/02/24      2            Picayune Item  Mississippi  2017  \n",
       "2      Lincoln  2017/02/24      2  The Ruston Daily Leader    Louisiana  2017  \n",
       "3  St. Bernard  2017/02/24      2    The St. Bernard Voice    Louisiana  2017  \n",
       "4  St. Bernard  2017/02/24      2    The St. Bernard Voice    Louisiana  2017  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>county</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>286080</td>\n",
       "      <td>285939</td>\n",
       "      <td>286080</td>\n",
       "      <td>286080</td>\n",
       "      <td>286080</td>\n",
       "      <td>286080</td>\n",
       "      <td>286080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>18334</td>\n",
       "      <td>18330</td>\n",
       "      <td>18334</td>\n",
       "      <td>18334</td>\n",
       "      <td>18334</td>\n",
       "      <td>18334</td>\n",
       "      <td>18334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louisiana</th>\n",
       "      <td>84229</td>\n",
       "      <td>84180</td>\n",
       "      <td>84229</td>\n",
       "      <td>84229</td>\n",
       "      <td>84229</td>\n",
       "      <td>84229</td>\n",
       "      <td>84229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mississippi</th>\n",
       "      <td>78849</td>\n",
       "      <td>78751</td>\n",
       "      <td>78849</td>\n",
       "      <td>78849</td>\n",
       "      <td>78849</td>\n",
       "      <td>78849</td>\n",
       "      <td>78849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>140337</td>\n",
       "      <td>140334</td>\n",
       "      <td>140337</td>\n",
       "      <td>140337</td>\n",
       "      <td>140337</td>\n",
       "      <td>140337</td>\n",
       "      <td>140337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Jersey</th>\n",
       "      <td>106042</td>\n",
       "      <td>106041</td>\n",
       "      <td>106042</td>\n",
       "      <td>106042</td>\n",
       "      <td>106042</td>\n",
       "      <td>106042</td>\n",
       "      <td>106042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Mexico</th>\n",
       "      <td>43034</td>\n",
       "      <td>43032</td>\n",
       "      <td>43034</td>\n",
       "      <td>43034</td>\n",
       "      <td>43034</td>\n",
       "      <td>43034</td>\n",
       "      <td>43034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tennessee</th>\n",
       "      <td>164587</td>\n",
       "      <td>164490</td>\n",
       "      <td>164587</td>\n",
       "      <td>164587</td>\n",
       "      <td>164587</td>\n",
       "      <td>164587</td>\n",
       "      <td>164587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>15554</td>\n",
       "      <td>15552</td>\n",
       "      <td>15554</td>\n",
       "      <td>15554</td>\n",
       "      <td>15554</td>\n",
       "      <td>15554</td>\n",
       "      <td>15554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  content  county    date   month  newspaper    year\n",
       "state                                                                    \n",
       "Arizona        286080   285939  286080  286080  286080     286080  286080\n",
       "Arkansas        18334    18330   18334   18334   18334      18334   18334\n",
       "Louisiana       84229    84180   84229   84229   84229      84229   84229\n",
       "Mississippi     78849    78751   78849   78849   78849      78849   78849\n",
       "Nevada         140337   140334  140337  140337  140337     140337  140337\n",
       "New Jersey     106042   106041  106042  106042  106042     106042  106042\n",
       "New Mexico      43034    43032   43034   43034   43034      43034   43034\n",
       "Tennessee      164587   164490  164587  164587  164587     164587  164587\n",
       "Wyoming         15554    15552   15554   15554   15554      15554   15554"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('state').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prime\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import csv\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df.category = df.category.str.lower()\n",
    "data = df[df.category=='summons'].content.values.tolist()\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove new line characters\n",
    "data = [str(sent).lower() for sent in data]\n",
    "\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "# Remove single word number quotes\n",
    "data = [re.sub(\"\\d+.\\d*\", \"\", sent) for sent in data]\n",
    "\n",
    "# Remove punctation\n",
    "data = [re.sub(\"\\!\", \"\", sent) for sent in data]\n",
    "\n",
    "# Remove blank \n",
    "temp = [x for x in data if x != '']\n",
    "\n",
    "data = temp\n",
    "pprint(data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['notice', 'for', 'publication', 'articles', 'of', 'organization', 'have', 'been', 'filed', 'in', 'the', 'office', 'of', 'the', 'arizona', 'corporation', 'commission', 'for', 'name', 'cc', 'solutions', 'llc', 'ii', 'the', 'address', 'of', 'the', 'known', 'place', 'of', 'business', 'is', 'murray', 'grey', 'dr', 'queen', 'creek', 'az', 'the', 'name', 'and', 'street', 'address', 'of', 'the', 'statutory', 'agent', 'is', 'claudia', 'romero', 'murray', 'grey', 'dr', 'queen', 'creek', 'az', 'iii', 'please', 'check', 'or', 'management', 'of', 'the', 'limited', 'liability', 'company', 'is', 'reserved', 'to', 'the', 'members', 'the', 'names', 'and', 'addresses', 'of', 'each', 'person', 'who', 'is', 'member', 'are', 'please', 'check', 'appropriate', 'box', 'claudia', 'romero', 'murray', 'grey', 'dr', 'queen', 'creek', 'az', 'member', 'manager', 'published', 'dec', 'jan']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prime\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\models\\phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['notice', 'for', 'publication', 'articles', 'of', 'organization', 'have', 'been', 'filed', 'in', 'the', 'office', 'of', 'the', 'arizona', 'corporation', 'commission', 'for', 'name', 'cc', 'solutions', 'llc', 'ii', 'the', 'address', 'of', 'the', 'known', 'place', 'of', 'business', 'is', 'murray', 'grey', 'dr', 'queen_creek', 'az', 'the', 'name', 'and', 'street', 'address', 'of', 'the', 'statutory', 'agent', 'is', 'claudia', 'romero', 'murray', 'grey', 'dr', 'queen_creek', 'az', 'iii', 'please', 'check', 'or', 'management', 'of', 'the', 'limited_liability_company', 'is', 'reserved', 'to', 'the', 'members', 'the', 'names', 'and', 'addresses', 'of', 'each', 'person', 'who', 'is', 'member', 'are', 'please_check_appropriate', 'box', 'claudia', 'romero', 'murray', 'grey', 'dr', 'queen_creek', 'az', 'member', 'manager', 'published', 'dec_jan']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "        #texts_out.append([token for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['notice', 'publication', 'article', 'organization', 'file', 'office', 'arizona', 'corporation', 'commission', 'name', 'solution', 'llc', 'address', 'know', 'place', 'business', 'murray', 'grey', 'queen_creek', 'name', 'street', 'address', 'statutory', 'agent', 'claudia', 'romero', 'murray', 'grey', 'queen_creek', 'check', 'management', 'limited_liability', 'company', 'reserve', 'member', 'name', 'address', 'person', 'member', 'check_appropriate', 'box', 'claudia', 'romero', 'murray', 'grey', 'queen_creek', 'member', 'manager', 'publish', 'dec_jan'], ['advertisement', 'bid', 'frontier', 'middle_school', 'drainage', 'improvement', 'county', 'school', 'district', 'casper_wyom', 'notice', 'hereby', 'give', 'pursuant', 'wyoming', 'statute', 'section', 'natrona', 'county', 'school', 'district', 'casper_wyoming', 'receive', 'sealed', 'bid', 'local', 'time', 'may', 'follow', 'description', 'work', 'installation', 'lineal', 'foot', 'storm', 'pipe', 'catch_basin', 'connection', 'downspout', 'miscellaneous', 'work', 'associate', 'installation', 'drainage', 'improvment', 'bid', 'must', 'sealed_envelope', 'statement', 'thereon', 'bid', 'enclose', 'frontier', 'middle_school', 'drainage', 'improvement', 'submit', 'wlc', 'pronghorn', 'street', 'casper_wyoming', 'state', 'time', 'bid', 'open', 'publicly', 'read_aloud', 'tabulate', 'project', 'manager', 'designee', 'state', 'time', 'place', 'alternative', 'site', 'designate', 'writing', 'post', 'wlc', 'prior', 'time', 'bid', 'opening', 'bid', 'may', 'withdraw', 'period', 'day', 'date', 'set', 'opening', 'thereof', 'natrona', 'county', 'school', 'district', 'casper_wyoming', 'reserve', 'reject', 'bid', 'waive_informalities', 'technicality', 'bidding', 'provide', 'however', 'bid', 'receive', 'time', 'specify', 'accompany', 'bid', 'guaranty', 'state', 'consider', 'bidding_document', 'include', 'specification', 'currently', 'available', 'engineer', 'wlc', 'engineering', 'surveying', 'planning', 'inc', 'pronghorn', 'casper_wyom', 'bidder', 'may', 'obtain', 'set', 'plan', 'partial_set', 'available', 'contact', 'wlc', 'engineer', 'electronic', 'bidding_document', 'charge', 'bid', 'guaranty', 'form', 'properly', 'execute', 'bid', 'bond', 'payable', 'natrona', 'county', 'school', 'district', 'amount', 'less', 'total', 'base', 'bid', 'amount', 'must', 'accompany', 'bid', 'note', 'bid', 'less', 'may', 'submit', 'cashiers_check', 'less', 'total', 'base', 'bid', 'amount', 'successful', 'bidder', 'require', 'execute', 'agreement', 'natrona', 'county', 'school', 'district', 'form', 'supply', 'bidding_document', 'day', 'notice', 'award', 'issue', 'notice', 'award', 'shall', 'serve', 'notice', 'agreement', 'ready', 'execution', 'bid', 'guaranty', 'shall', 'forfeit', 'liquidated_damage', 'bidder', 'fail', 'execute', 'agreement', 'day', 'notice', 'issue', 'fail', 'provide', 'proper', 'bond', 'form', 'guaranty', 'approve', 'bid', 'guaranty', 'bid', 'bond', 'shall', 'execute', 'surety', 'guarantee', 'company', 'authorize', 'business', 'wyom', 'attorney', 'fact', 'execute', 'bond', 'behalf', 'surety', 'shall', 'affix', 'certify', 'current', 'copy', 'power', 'attorney', 'surety', 'type', 'bid', 'guaranty', 'accept', 'natrona', 'county', 'school', 'district', 'may', 'proceed', 'bid', 'guaranty', 'agreement', 'execute', 'contractor', 'performance', 'labor', 'material', 'payment', 'bond', 'furnish', 'require', 'specify', 'time', 'elapse', 'bid', 'may', 'withdraw', 'bid', 'reject', 'notice', 'hereby', 'give', 'preference', 'grant', 'wyom', 'contractors_subcontractor', 'laborer', 'materials_supplie', 'equipment_machinery', 'provisions_produced', 'manufacture', 'supply', 'grown', 'wyom', 'require', 'section', 'pre', 'bid', 'conference', 'hold', 'contractor', 'encourage', 'tour', 'site', 'time', 'natrona', 'county', 'school', 'district', 'publish', 'april', 'may', 'legal'], ['notice', 'sale', 'apn', 'order', 'warn', 'sale', 'property', 'imminent_unless', 'pay', 'amount', 'specify', 'notice', 'sale', 'date', 'could_lose', 'home', 'even', 'amount', 'dispute', 'must', 'act', 'sale', 'date', 'question', 'call', 'sale', 'trustee', 'homeowner', 'association', 'service', 'inc', 'need', 'assistance', 'call', 'ombudsman', 'office', 'nevada', 'real', 'estate', 'division', 'telephone', 'number', 'immediately', 'november', 'oclock', 'homeowner', 'association', 'service', 'inc', 'agent', 'paradise_spa', 'owner', 'association', 'inc', 'pursuant', 'notice', 'claim', 'homeowner', 'assessment', 'date', 'march', 'execute', 'michael', 'randolph', 'designate', 'agent', 'paradise_spa', 'owner', 'association', 'inc', 'record', 'march', 'book', 'official_record', 'document', 'clark', 'county', 'nevada', 'lien', 'properly', 'assess', 'record', 'pursuant', 'nevada', 'revised_statute', 'favor', 'paradise_spa', 'owner', 'association', 'inc', 'reason', 'breach', 'assessment', 'obligation', 'secured_thereby', 'notice', 'default', 'election', 'sell', 'record', 'june', 'book', 'document', 'clark', 'county', 'nevada', 'sell', 'public', 'auction', 'high', 'bidder', 'lawful_money', 'united_state', 'america', 'front_entrance', 'nevada', 'legal', 'news', 'paradise_spa', 'owner', 'association', 'inc', 'locate', 'south', 'fourth', 'street', 'las_vegas', 'nevada', 'without_covenant', 'warranty_express', 'implied_regard', 'title', 'possession', 'encumbranc', 'right', 'title', 'interest', 'owner', 'equity', 'right', 'redemption', 'real', 'property', 'situate', 'county', 'clark', 'state', 'nevada', 'describe', 'follow', 'owner', 'record', 'ameristate', 'investment', 'llc', 'commonly_known', 'las_vegas', 'blvd', 'las_vegas', 'aka', 'las_vegas', 'blvd', 'las_vegas', 'continue', 'page', 'page', 'notice', 'sale', 'apn', 'order', 'parcel', 'undivided', 'interest', 'common', 'area', 'establish', 'lot', 'map', 'paradise_spa', 'unit', 'show', 'map', 'thereof', 'record', 'april', 'file', 'book', 'plat', 'page', 'amend', 'plat', 'paradise_spa', 'unit', 'show', 'map', 'thereof', 'record', 'march', 'file', 'book', 'plat', 'page', 'office', 'county', 'recorder', 'clark', 'county', 'nevada', 'parcel', 'unit', 'plat', 'paradise_spa', 'unit', 'show', 'map', 'thereof', 'file', 'book', 'plat', 'page', 'office', 'county', 'recorder', 'county', 'recorder', 'clark', 'county', 'nevada', 'purpose', 'satisfy', 'assessment', 'obligation', 'secure', 'say', 'assessment', 'lien', 'wit', 'interest', 'provide', 'law', 'subsequent', 'monthly', 'homeowners_association', 'due', 'fees_charge', 'expense', 'advance', 'homeowners_association', 'agent', 'term', 'assessment', 'date', 'october', 'homeowner', 'association', 'service', 'inc', 'agent', 'paradise_spa', 'owner', 'association', 'inc', 'mike', 'randolph', 'certified', 'manager', 'phone_fax', 'publish', 'line', 'land', 'situate', 'las_vegas', 'judicial', 'township', 'publish', 'notice', 'sale', 'nevada', 'legal', 'news', 'time', 'october', 'november', 'november', 'publish', 'nevada', 'legal', 'news', 'october', 'november'], ['summon', 'superior', 'court', 'state', 'arizona', 'county', 'pinal', 'assign', 'honorable', 'stephen', 'mccarville', 'gregorio', 'lara', 'rodriguez', 'single_man', 'ricky', 'rodriguez', 'castruita', 'single_man', 'plaintiff', 'jose', 'ventura', 'jane_doe', 'ventura', 'married_couple', 'cazare', 'lopez', 'jane_doe', 'cazare', 'lopez', 'married_couple', 'red', 'valley', 'wall', 'system', 'arizona', 'limited_liability', 'company', 'red', 'valley', 'landscape', 'arizona', 'limited_liability', 'company', 'jane', 'black_corporation', 'white_partnership', 'defendant', 'name', 'defendant', 'hereby', 'summon', 'require', 'appear', 'defend', 'entitle', 'action', 'entitle', 'court', 'day', 'day', 'exclusive', 'day', 'service', 'service', 'summon', 'serve', 'state', 'arizona', 'day', 'day', 'exclusive', 'date', 'service', 'serve', 'outside', 'state', 'arizona', 'hereby', 'notify', 'case', 'fail', 'judgment', 'default', 'render', 'relief_demand', 'complaint', 'appear', 'defend', 'mean', 'must', 'time', 'period', 'file', 'answer', 'plead', 'clerk', 'superior', 'court', 'accompany', 'proper', 'filing', 'fee', 'serve', 'copy', 'answer', 'responsive_plead', 'attorney', 'plaintiff', 'ada', 'notification', 'request', 'reasonable_accommodation', 'person', 'disability', 'must', 'make', 'court', 'party', 'least_three', 'work', 'day', 'advance', 'schedule', 'court', 'proceeding', 'name', 'address', 'telephone', 'number', 'attorney', 'plaintiff', 'cole', 'leal', 'joseph', 'leal', 'west', 'casa_grande', 'lake', 'boulevard', 'north', 'casa_grande', 'arizona', 'date', 'day', 'march', 'amanda_stanford', 'clerk', 'superior', 'court', 'aubrey', 'kendall', 'deputy', 'clerk', 'serive', 'publication', 'complete', 'day', 'date', 'first', 'publication', 'obtain', 'co', 'complaint', 'action', 'contact', 'write', 'joseph', 'leal', 'iii', 'cole', 'leal', 'casa_grande', 'lake', 'blvd', 'casa_grande', 'pub', 'may', 'june'], ['public', 'notice', 'follow', 'vehicle', 'auction', 'transmission', 'new', 'nashville', 'hwy', 'murfreesboro', 'dodge', 'kahmexicano', 'auto_repair', 'maple', 'lebanon', 'chevy', 'bhctfchavas', 'auto', 'service', 'lowry', 'st', 'smryna', 'acura', 'uaakm', 'auto', 'sale', 'repair', 'nashville', 'toyota', 'esnzhwy', 'auto_repair', 'garden', 'st', 'columbia', 'ford', 'afpajo', 'body', 'paint', 'shop', 'ash', 'st', 'murfreesboro', 'dodge', 'esd', 'saab', 'nolensville', 'auto', 'care', 'ford', 'myuaa', 'auto_repair', 'lebanon', 'rd', 'old_hickory', 'mazda', 'jmkdiscount', 'transmission', 'main', 'hendersonville', 'trailer', 'ktaepo', 'auto_repair', 'smith', 'spring', 'nashville', 'chevy', 'ndasmorris', 'auto', 'murfreesboro', 'lavergne', 'chevy', 'nctkeuro', 'fix', 'royal', 'oak', 'blvd', 'franklin', 'wbavae', 'volk', 'wvwakp', 'wbaglpexpress', 'towing', 'cornelia', 'nashville', 'kia', 'knafb', 'ford', 'mruwlb', 'chevy', 'nd', 'chevy', 'hyundai', 'pdheh', 'nissan', 'alc', 'honda', 'jhmeg', 'chevy', 'jeep', 'gzvcinitial', 'publication']]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 3), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 3), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 3), (21, 3), (22, 3), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 3), (31, 1), (32, 2), (33, 1), (34, 1), (35, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('address', 3),\n",
       "  ('agent', 1),\n",
       "  ('arizona', 1),\n",
       "  ('article', 1),\n",
       "  ('box', 1),\n",
       "  ('business', 1),\n",
       "  ('check', 1),\n",
       "  ('check_appropriate', 1),\n",
       "  ('claudia', 2),\n",
       "  ('commission', 1),\n",
       "  ('company', 1),\n",
       "  ('corporation', 1),\n",
       "  ('dec_jan', 1),\n",
       "  ('file', 1),\n",
       "  ('grey', 3),\n",
       "  ('know', 1),\n",
       "  ('limited_liability', 1),\n",
       "  ('llc', 1),\n",
       "  ('management', 1),\n",
       "  ('manager', 1),\n",
       "  ('member', 3),\n",
       "  ('murray', 3),\n",
       "  ('name', 3),\n",
       "  ('notice', 1),\n",
       "  ('office', 1),\n",
       "  ('organization', 1),\n",
       "  ('person', 1),\n",
       "  ('place', 1),\n",
       "  ('publication', 1),\n",
       "  ('publish', 1),\n",
       "  ('queen_creek', 3),\n",
       "  ('reserve', 1),\n",
       "  ('romero', 2),\n",
       "  ('solution', 1),\n",
       "  ('statutory', 1),\n",
       "  ('street', 1)]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=20,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -7.583538134840006\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-eacbdc545be3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Compute Coherence Score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcoherence_model_lda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_lemmatized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c_v'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcoherence_lda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoherence_model_lda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_coherence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nCoherence Score: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoherence_lda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\models\\coherencemodel.py\u001b[0m in \u001b[0;36mget_coherence\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_coherence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;34m\"\"\"Return coherence value based on pipeline parameters.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mconfirmed_measures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_coherence_per_topic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggregate_measures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfirmed_measures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\models\\coherencemodel.py\u001b[0m in \u001b[0;36mget_coherence_per_topic\u001b[1;34m(self, segmented_topics, with_std, with_support)\u001b[0m\n\u001b[0;32m    411\u001b[0m             \u001b[0msegmented_topics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accumulator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimate_probabilities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegmented_topics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_support\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwith_support\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\models\\coherencemodel.py\u001b[0m in \u001b[0;36mestimate_probabilities\u001b[1;34m(self, segmented_topics)\u001b[0m\n\u001b[0;32m    401\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeyed_vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accumulator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accumulator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\topic_coherence\\probability_estimation.py\u001b[0m in \u001b[0;36mp_boolean_sliding_window\u001b[1;34m(texts, segmented_topics, dictionary, window_size, processes)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0maccumulator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallelWordOccurrenceAccumulator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"using %s to estimate probabilities from sliding windows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccumulator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0maccumulator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\topic_coherence\\text_analysis.py\u001b[0m in \u001b[0;36maccumulate\u001b[1;34m(self, texts, window_size)\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[0minterrupted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m         \u001b[0maccumulators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate_workers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterrupted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge_accumulators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccumulators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\topic_coherence\\text_analysis.py\u001b[0m in \u001b[0;36mterminate_workers\u001b[1;34m(self, input_q, output_q, workers, interrupted)\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[0maccumulators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccumulators\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0maccumulators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_q\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%d accumulators retrieved from output queue\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccumulators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;31m# unserialize the data after having released the lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=1, step=1):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=num_topics, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=1, limit=100, step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "from matplotlib import pyplot  as plt\n",
    "\n",
    "limit=100; start=1; step=5;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=20,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('clean_data.txt', 'w')\n",
    "\n",
    "for data in data_lemmatized:\n",
    "    file.write(str(data))\n",
    "\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
